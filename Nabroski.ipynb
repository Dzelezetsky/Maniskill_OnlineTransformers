{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import gymnasium as gym\n",
    "from mani_skill.utils import gym_utils\n",
    "from mani_skill.utils.wrappers.flatten import FlattenActionSpaceWrapper\n",
    "from mani_skill.utils.wrappers.record import RecordEpisode\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/anaconda3/envs/rate/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/daniil/anaconda3/envs/rate/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env_kwargs = dict(obs_mode=\"state\", render_mode=\"rgb_array\", sim_backend=\"gpu\")\n",
    "env_kwargs[\"control_mode\"] = \"pd_joint_delta_pos\"\n",
    "    \n",
    "envs = gym.make('PickCube-v1', num_envs=50, reconfiguration_freq=None, **env_kwargs)\n",
    "\n",
    "rb = ReplayBuffer(envs , 50, contex, 1000000, 'cuda', 'cuda')\n",
    "\n",
    "rb.pos = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 10, 42]),\n",
       " torch.Size([512, 10, 42]),\n",
       " torch.Size([512, 8]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = rb.sample(512)\n",
    "\n",
    "batch.obs.shape, batch.next_obs.shape, batch.actions.shape , batch.rewards.shape , batch.dones.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "contex = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.zeros(50,contex,42)\n",
    "next_obs = torch.zeros(50,contex,42)\n",
    "actions = torch.zeros(50,8)\n",
    "rewards = torch.zeros(50)\n",
    "dones = torch.zeros(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.add(obs, next_obs, actions, rewards, dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReplayBufferSample:\n",
    "    obs: torch.Tensor\n",
    "    next_obs: torch.Tensor\n",
    "    actions: torch.Tensor\n",
    "    rewards: torch.Tensor\n",
    "    dones: torch.Tensor\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, env, num_envs: int, contex: int, buffer_size: int, storage_device: torch.device, sample_device: torch.device):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.pos = 0\n",
    "        self.full = False\n",
    "        self.num_envs = num_envs\n",
    "        self.storage_device = storage_device\n",
    "        self.sample_device = sample_device\n",
    "        self.per_env_buffer_size = buffer_size // num_envs\n",
    "        self.obs = torch.zeros((self.per_env_buffer_size, self.num_envs, contex) + env.single_observation_space.shape).to(storage_device)\n",
    "        self.next_obs = torch.zeros((self.per_env_buffer_size, self.num_envs, contex) + env.single_observation_space.shape).to(storage_device)\n",
    "        self.actions = torch.zeros((self.per_env_buffer_size, self.num_envs) + env.single_action_space.shape).to(storage_device)\n",
    "        self.logprobs = torch.zeros((self.per_env_buffer_size, self.num_envs)).to(storage_device)\n",
    "        self.rewards = torch.zeros((self.per_env_buffer_size, self.num_envs)).to(storage_device)\n",
    "        self.dones = torch.zeros((self.per_env_buffer_size, self.num_envs)).to(storage_device)\n",
    "        self.values = torch.zeros((self.per_env_buffer_size, self.num_envs)).to(storage_device) \n",
    "\n",
    "    def add(self, obs: torch.Tensor, next_obs: torch.Tensor, action: torch.Tensor, reward: torch.Tensor, done: torch.Tensor):\n",
    "        if self.storage_device == torch.device(\"cpu\"):\n",
    "            obs = obs.cpu()\n",
    "            next_obs = next_obs.cpu()\n",
    "            action = action.cpu()\n",
    "            reward = reward.cpu()\n",
    "            done = done.cpu()\n",
    "\n",
    "        self.obs[self.pos] = obs\n",
    "        self.next_obs[self.pos] = next_obs\n",
    "\n",
    "        self.actions[self.pos] = action\n",
    "        self.rewards[self.pos] = reward\n",
    "        self.dones[self.pos] = done\n",
    "\n",
    "        self.pos += 1\n",
    "        if self.pos == self.per_env_buffer_size:\n",
    "            self.full = True\n",
    "            self.pos = 0\n",
    "    def sample(self, batch_size: int):\n",
    "        if self.full:\n",
    "            batch_inds = torch.randint(0, self.per_env_buffer_size, size=(batch_size, ))\n",
    "        else:\n",
    "            batch_inds = torch.randint(0, self.pos, size=(batch_size, ))\n",
    "        env_inds = torch.randint(0, self.num_envs, size=(batch_size, ))\n",
    "        return ReplayBufferSample(\n",
    "            obs=self.obs[batch_inds, env_inds].to(self.sample_device),\n",
    "            next_obs=self.next_obs[batch_inds, env_inds].to(self.sample_device),\n",
    "            actions=self.actions[batch_inds, env_inds].to(self.sample_device),\n",
    "            rewards=self.rewards[batch_inds, env_inds].to(self.sample_device),\n",
    "            dones=self.dones[batch_inds, env_inds].to(self.sample_device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
